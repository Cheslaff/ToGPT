{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Many To Many RNN for Language Modeling\n",
        "Previously I used LLM to help with writin code, but here everything is developed by me!<br>\n",
        "As for dataset I used \"Silent Dan\" by Ozon671games3 (short description of this audiobook: Ce Pizda)"
      ],
      "metadata": {
        "id": "wWGXI7j6eOLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import random"
      ],
      "metadata": {
        "id": "gilFDVg9u2WL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\""
      ],
      "metadata": {
        "id": "8azqlAXL9lpC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(\"data.txt\", \"r\").read()\n",
        "\n",
        "chars = sorted(set(text))\n",
        "vocab_size = len(chars)\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for ch, i in stoi.items()}"
      ],
      "metadata": {
        "id": "LNYsXurbuOf_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.ih1 = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.h1h2 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "    self.dropout = nn.Dropout(0.1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.h2h3 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "    self.h3o = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def init_hidden(self, device):\n",
        "    return [torch.zeros((1, self.hidden_size), device=device) for _ in range(3)]\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    h1, h2, h3 = hidden\n",
        "    cat_inp = torch.cat((input, h1), dim=1)\n",
        "    h1_ = self.relu(self.dropout(self.ih1(cat_inp)))\n",
        "\n",
        "    h1h2 = torch.cat((h1_, h2), dim=1)\n",
        "    h2_ = self.relu(self.dropout(self.h1h2(h1h2)))\n",
        "\n",
        "    h2h3 = torch.cat((h2_, h3), dim=1)\n",
        "    h3_ = self.relu(self.dropout(self.h2h3(h2h3)))\n",
        "\n",
        "    o = self.h3o(h3_)\n",
        "\n",
        "    return o, (h1_, h2_, h3_)"
      ],
      "metadata": {
        "id": "r9Qcs6nVue7K"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = output_size = vocab_size\n",
        "hidden_size = 32\n",
        "\n",
        "rnn = RNN(input_size, hidden_size, output_size).to(device)\n",
        "optim = torch.optim.Adam(rnn.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ffZCei-Q3X04"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(start=\"\", len=10):\n",
        "  chars = [stoi[ch] for ch in start]\n",
        "  h1, h2, h3 = rnn.init_hidden(device)\n",
        "  for i in range(len):\n",
        "    input = F.one_hot(torch.tensor([chars[-1]]), vocab_size).to(device)\n",
        "    logits, (h1, h2, h3) = rnn(input, (h1, h2, h3))\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    ix = torch.multinomial(probs, 1).item()\n",
        "    chars.append(ix)\n",
        "  return \"\".join([itos[ch] for ch in chars])"
      ],
      "metadata": {
        "id": "0gIjlY2Z7Cmq"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "0rq2hsRi_faj"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 16\n",
        "epochs = 50\n",
        "block_per_epoch = 3_000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  start_idx = torch.randint(0, len(text)-block_per_epoch, (1,)).item()\n",
        "  for i in tqdm(range(start_idx, start_idx+block_per_epoch)):\n",
        "    chunk = text[i:i+seq_len]\n",
        "    target = text[i+1:i+seq_len+1]\n",
        "    input = [stoi[ch] for ch in chunk]\n",
        "    target = torch.tensor([stoi[ch] for ch in target]).to(device)\n",
        "    input = F.one_hot(torch.tensor(input), vocab_size).to(device)\n",
        "\n",
        "    h1, h2, h3 = rnn.init_hidden(device)\n",
        "    loss_chunk = 0\n",
        "    for x in range(len(input)):\n",
        "      inp = input[x].unsqueeze(0)\n",
        "      logits, (h1, h2, h3) = rnn(inp, (h1, h2, h3))\n",
        "      tg = target[x].unsqueeze(0)\n",
        "      loss = loss_fn(logits, tg)\n",
        "      loss_chunk += loss\n",
        "    optim.zero_grad()\n",
        "    loss_chunk.backward()\n",
        "    optim.step()\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f\"Loss: {loss_chunk.item()}\")\n",
        "    print(generate(random.choice(chars), 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irGQHa1H3pZN",
        "outputId": "5df15939-e5a0-4d88-9ac2-07eb27af684d"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [01:05<00:00, 45.98it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.55it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.51it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.18it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.60it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.21it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.16it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.82it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.51it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 46.317596435546875\n",
            "котя. нерал\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [01:04<00:00, 46.32it/s]\n",
            "100%|██████████| 3000/3000 [01:05<00:00, 46.12it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.72it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.51it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.16it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.25it/s]\n",
            "100%|██████████| 3000/3000 [01:05<00:00, 45.86it/s]\n",
            "100%|██████████| 3000/3000 [01:05<00:00, 45.96it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.25it/s]\n",
            "100%|██████████| 3000/3000 [01:05<00:00, 45.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 35.73217010498047\n",
            "Эд, лань-тр\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [01:04<00:00, 46.65it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.50it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.29it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.59it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.36it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.36it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.32it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.23it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.75it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 45.22844696044922\n",
            "вешишь! Пру\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [01:05<00:00, 46.04it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.41it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.52it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.21it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.68it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.28it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.58it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.76it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.48it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 45.88179016113281\n",
            "Я нувась тя\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [01:04<00:00, 46.59it/s]\n",
            "100%|██████████| 3000/3000 [01:05<00:00, 46.09it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.83it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.76it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.31it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.84it/s]\n",
            "100%|██████████| 3000/3000 [01:03<00:00, 46.94it/s]\n",
            "100%|██████████| 3000/3000 [01:05<00:00, 46.12it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.58it/s]\n",
            "100%|██████████| 3000/3000 [01:04<00:00, 46.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 35.8166618347168\n",
            "Вокохсялж?\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate(\"Дэн \", 1000))"
      ],
      "metadata": {
        "id": "V5QezSaU5LTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f8f8ec-e832-44b6-eff6-e07467ba4f25"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Дэн я  нину.\n",
            "отямелась, ко, и Да, я отдес под ссдободевил т грою дамая в ной тейгей И зашнацо с что Я ве.\n",
            "Я выш сВыварава приби мне ист менашинет.\n",
            "«тдеди.\n",
            "Ннончарна? Васкией.\n",
            "претол подвекесь вы коонам зомофия выбесле. по всё подкяникоющака вамало баваннот, и уприл зевкоки, .\n",
            "М ому, у мней\n",
            "Мы, в зде, казко?.\n",
            "е савнитовом, зди так эедало над короашавал, каки нешомо вызавиня\n",
            "я в про. оботозром. Квно осты ю, с вашажиячий дувем.\n",
            "Дошимскавюй всё, вва ки креза ежибо ко вомо обузалаити приетно...\n",
            "Качемсяю подё проя дежьсьхчя дне пол Даловивтцея, педывесяе, прапраЯ цивинланинячит ожок отобел, вовенивнушю я ди рамкоене за вако, нри на посчто, это Тевко стубороверазоли! Чтлом.\n",
            "Я издот нипал котезо сказяюхно чтойю. Я сили имкоесста, скокия ма пмачего.\n",
            "Я нежу меня.\n",
            "Доненижатаз и, каминте-тавеебя приноек.\n",
            "«Луизи.\n",
            "вы.\n",
            "Кежко о, воячиуголожоонуха было ке?\n",
            "Зотьжигошужинай в с ук и это я я не с чтронготловны! немик -па за.\n",
            "Но и премть потсолачна. отнамали?\n",
            "ешири долок чтотити азйзнелях но что  вмашросе.... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Okay, I can believe ozon671games3 could write something like this"
      ],
      "metadata": {
        "id": "uXsznPRueGTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(rnn.state_dict(), \"/content/params.pth\")"
      ],
      "metadata": {
        "id": "GTydhEryejSP"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EI-I5TbOe-8b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}